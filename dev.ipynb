{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242dda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/astarag/interventions-project/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n",
      "ðŸš¨ `interventions_config` is part of LlamaModel.__init__'s signature, but not documented. Make sure to add it to the docstring of the function in /home/recoverx/astarag/interventions-project/interventions_rl/model/llama.py.\n",
      "ðŸš¨ `interventions_config` is part of LlamaForCausalLM.__init__'s signature, but not documented. Make sure to add it to the docstring of the function in /home/recoverx/astarag/interventions-project/interventions_rl/model/llama.py.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54454940cd4f46d1a49cf5b7bd38e5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partial state dict:   0%|          | 1/311 [00:00<02:20,  2.20it/s]\u001b[32m2026-02-08 16:09:38.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.0.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.0.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.1.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.1.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.2.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.2.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.3.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.3.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.4.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.4.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.5.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.5.self_attn.k_norm.weight'\u001b[0m\n",
      "Building partial state dict:  21%|â–ˆâ–ˆ        | 65/311 [00:00<00:01, 153.78it/s]\u001b[32m2026-02-08 16:09:38.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.6.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.6.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.7.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.7.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.8.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.8.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.9.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.9.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.10.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.10.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.11.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.11.self_attn.k_norm.weight'\u001b[0m\n",
      "Building partial state dict:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 130/311 [00:00<00:00, 276.70it/s]\u001b[32m2026-02-08 16:09:38.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.12.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.12.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.13.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.13.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.14.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.14.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.15.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.15.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.16.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.16.self_attn.k_norm.weight'\u001b[0m\n",
      "Building partial state dict:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 186/311 [00:00<00:00, 348.06it/s]\u001b[32m2026-02-08 16:09:38.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.17.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.17.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.18.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.18.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.19.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.19.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.20.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.20.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.21.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.21.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.22.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.22.self_attn.k_norm.weight'\u001b[0m\n",
      "Building partial state dict:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 249/311 [00:00<00:00, 424.31it/s]\u001b[32m2026-02-08 16:09:38.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.23.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.23.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.24.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:38.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.24.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:39.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.25.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:39.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.25.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:39.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.26.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:39.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.26.self_attn.k_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:39.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.27.self_attn.q_norm.weight'\u001b[0m\n",
      "\u001b[32m2026-02-08 16:09:39.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mbuild_partial_state_dict\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mMissing for src_name='model.layers.27.self_attn.k_norm.weight'\u001b[0m\n",
      "Building partial state dict: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 311/311 [00:01<00:00, 303.34it/s]\n",
      "\u001b[32m2026-02-08 16:09:40.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mload_hf_into_custom_model\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mParameter stats â€” total: 1735251456, trainable: 14683648\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters:     1735251456\n",
      "Trainable parameters: 14683648\n",
      "Copied: 255 | Skipped (shape): 0 | Skipped (missing): 224 | Skipped (intervention): 0\n"
     ]
    }
   ],
   "source": [
    "from interventions_rl.model import load_model, qwen3, interventions_utils\n",
    "import torch\n",
    "from transformers import AutoConfig\n",
    "from interventions_rl.model import qwen3\n",
    "\n",
    "hf_model_name_or_path = \"Qwen/Qwen3-1.7B\"\n",
    "hf_config = AutoConfig.from_pretrained(\n",
    "    hf_model_name_or_path,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "custom_model = qwen3.Qwen3ForCausalLM(\n",
    "    interventions_config=interventions_utils.InterventionsConfig(\n",
    "        intervention_type=\"LoreftIntervention\",\n",
    "        intervention_layers=\"all\",\n",
    "        low_rank_dimension=128,\n",
    "        dropout=0.0,\n",
    "        act_fn=\"gelu\",\n",
    "    ),\n",
    "    config=hf_config,\n",
    ")\n",
    "\n",
    "# 2) Load HF weights into the overlapping parts, skipping interventions\n",
    "report, module = load_model.load_hf_into_custom_model(\n",
    "    hf_model_name_or_path=hf_model_name_or_path,\n",
    "    custom_model=custom_model,\n",
    "    hf_config=hf_config,\n",
    "    map_dtype=torch.float32,  # optional casting\n",
    "    map_device=torch.device(\"cuda\"),  # optional device move\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(report.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d15bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e50d4ece32445c2acdc6e759f8e01cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd832336cee942dbad9e442d3e46b7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a287e1151eb49218fe8b9bda04723f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building partial state dict: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147/147 [00:00<00:00, 281.67it/s]\n",
      "\u001b[32m2026-02-08 16:12:47.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36minterventions_rl.model.load_model\u001b[0m:\u001b[36mload_hf_into_custom_model\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mParameter stats â€” total: 1244205056, trainable: 8390656\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters:     1244205056\n",
      "Trainable parameters: 8390656\n",
      "Copied: 147 | Skipped (shape): 0 | Skipped (missing): 96 | Skipped (intervention): 0\n"
     ]
    }
   ],
   "source": [
    "from interventions_rl.model import llama\n",
    "\n",
    "hf_model_name_or_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "hf_config = AutoConfig.from_pretrained(\n",
    "    hf_model_name_or_path,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "custom_model = llama.LlamaForCausalLM(\n",
    "    interventions_config=interventions_utils.InterventionsConfig(\n",
    "        intervention_type=\"LoreftIntervention\",\n",
    "        intervention_layers=\"all\",\n",
    "        low_rank_dimension=128,\n",
    "        dropout=0.0,\n",
    "        act_fn=\"gelu\",\n",
    "    ),\n",
    "    config=hf_config,\n",
    ")\n",
    "\n",
    "# 2) Load HF weights into the overlapping parts, skipping interventions\n",
    "report, module = load_model.load_hf_into_custom_model(\n",
    "    hf_model_name_or_path=hf_model_name_or_path,\n",
    "    custom_model=custom_model,\n",
    "    hf_config=hf_config,\n",
    "    map_dtype=torch.float32,  # optional casting\n",
    "    map_device=torch.device(\"cuda\"),  # optional device move\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(report.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804cd594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006743788702302139"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8390656 / 1244205056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a2de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
